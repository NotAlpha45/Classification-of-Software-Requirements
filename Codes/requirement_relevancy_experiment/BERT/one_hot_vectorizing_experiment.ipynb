{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTEN Oversampling Experiment\n",
    "In This notebook we will be using the SMOTEN oversampling technique to balance the dataset. We will be using the same dataset as the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Ti Laptop GPU'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(MY_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"caching_allocator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reqs_statement</th>\n",
       "      <th>action_part</th>\n",
       "      <th>actor_part</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user submit job associate cost execution time ...</td>\n",
       "      <td>submit job associate cost execution time deadline</td>\n",
       "      <td>user</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user establish cost unit time and submit job</td>\n",
       "      <td>establish cost unit time and submit job</td>\n",
       "      <td>user</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user monitor job submit status</td>\n",
       "      <td>monitor job submit status</td>\n",
       "      <td>user</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user cancel job submit</td>\n",
       "      <td>cancel job submit</td>\n",
       "      <td>user</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user check credit balance</td>\n",
       "      <td>check credit balance</td>\n",
       "      <td>user</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      reqs_statement  \\\n",
       "0  user submit job associate cost execution time ...   \n",
       "1       user establish cost unit time and submit job   \n",
       "2                     user monitor job submit status   \n",
       "3                             user cancel job submit   \n",
       "4                          user check credit balance   \n",
       "\n",
       "                                         action_part actor_part     label  \n",
       "0  submit job associate cost execution time deadline       user  relevant  \n",
       "1            establish cost unit time and submit job       user  relevant  \n",
       "2                          monitor job submit status       user  relevant  \n",
       "3                                  cancel job submit       user  relevant  \n",
       "4                               check credit balance       user  relevant  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirement_relevancy_dataset = pd.read_csv(\n",
    "    \"../../../Datasets/irrelevant_requirements_dataset/irrelevant_requirements_dataset.csv\",\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "\n",
    "requirement_relevancy_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_X = requirement_relevancy_dataset[\"reqs_statement\"]\n",
    "label_y = requirement_relevancy_dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of the requirements:  123\n"
     ]
    }
   ],
   "source": [
    "# Get the max length of the requirements\n",
    "max_len = 0\n",
    "for req in requirements_X:\n",
    "    if len(req.split()) > max_len:\n",
    "        max_len = len(req.split())\n",
    "\n",
    "print(\"Max length of the requirements: \", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "616     True\n",
       "617     True\n",
       "618     True\n",
       "619    False\n",
       "620    False\n",
       "Name: relevant, Length: 621, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the labels\n",
    "label_y = pd.get_dummies(label_y, drop_first=True)\n",
    "label_y = label_y[\"relevant\"]\n",
    "label_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    requirements_X, label_y, test_size=0.15, random_state=42, stratify=label_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((527,), (527,), (94,), (94,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = SMOTEN(\n",
    "    random_state=42, sampling_strategy=\"all\"\n",
    ").fit_resample(X_train.values.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((946, 1), (946,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape, y_train_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Befroe Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant\n",
       "True     473\n",
       "False     54\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant\n",
       "True     473\n",
       "False    473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled = X_train_resampled.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant\n",
       "True     84\n",
       "False    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(946,) (94,)\n",
      "(946,) (94,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_resampled.shape, X_test.shape)\n",
    "print(y_train_resampled.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment With NLP Models\n",
    "\n",
    "In this segment, I will be experimenting with different NLP models to see which one performs the best. I will be using the following models: DistilBERT, ROBERA, DistilBERT, and XLNet. I will be using the HuggingFace library to implement these models. I will be using the same data as the previous notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT Model\n",
    "\n",
    "DistilBERT is a smaller version of BERT. It is trained to be faster and more efficient than BERT. It is also trained to be more memory efficient. It is trained using the same data as BERT. It is trained using a technique called knowledge distillation. This technique is used to compress a large model into a smaller model. The smaller model is trained to mimic the behavior of the larger model. The smaller model is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    DistilBertModel,\n",
    "    DistilBertTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tokenized_train_data_X = bert_tokenizer(\n",
    "        X_train_resampled.tolist(),\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    tokenized_test_data_X = bert_tokenizer(\n",
    "        X_test.tolist(),\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = DistilBertModel.from_pretrained(\n",
    "    \"../../../Models/requirement_relevancy_experiment/NLP_models/my_distilbert_model/\",\n",
    "    # device_map=MY_DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Precision Calculation\n",
    "\n",
    "Mixed precsion is the use of both 16 and 32 bit float to optimize memory during training to make it run faster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cuda.amp.autocast() is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    X_train_outputs = bert_model(**tokenized_train_data_X)\n",
    "    X_test_outputs = bert_model(**tokenized_test_data_X)\n",
    "\n",
    "# outputs = bert_model(**tokenized_text_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_last_hidden_states = X_train_outputs.last_hidden_state\n",
    "X_test_last_hidden_states = X_test_outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([946, 100, 768]), torch.Size([94, 100, 768]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_last_hidden_states.shape, X_test_last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((946, 76800), (94, 76800))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_X_train_last_hidden_states = X_train_last_hidden_states.reshape(\n",
    "    X_train_last_hidden_states.shape[0], -1\n",
    ").detach().numpy()\n",
    "\n",
    "reshaped_X_test_last_hidden_states = X_test_last_hidden_states.reshape(\n",
    "    X_test_last_hidden_states.shape[0], -1\n",
    ").detach().numpy()\n",
    "\n",
    "reshaped_X_train_last_hidden_states.shape, reshaped_X_test_last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((946, 76800), (946,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_X_train_last_hidden_states.shape, y_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94, 76800), (94,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_X_test_last_hidden_states.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the reshaped_X_train_last_hidden_states and reshaped_X_test_last_hidden_states\n",
    "np.savetxt(\n",
    "    \"../../../Datasets/irrelevant_requirements_dataset/model_state_outputs/distilbert/reshaped_X_train_last_hidden_states.csv\",\n",
    "    reshaped_X_train_last_hidden_states,\n",
    ")\n",
    "\n",
    "np.savetxt(\n",
    "    \"../../../Datasets/irrelevant_requirements_dataset/model_state_outputs/distilbert/reshaped_X_test_last_hidden_states.csv\",\n",
    "    reshaped_X_test_last_hidden_states,\n",
    ")\n",
    "\n",
    "# Save the y_train and y_test\n",
    "np.savetxt(\n",
    "    \"../../../Datasets/irrelevant_requirements_dataset/model_state_outputs/distilbert/y_train.csv\",\n",
    "    y_train_resampled,\n",
    ")\n",
    "\n",
    "np.savetxt(\n",
    "    \"../../../Datasets/irrelevant_requirements_dataset/model_state_outputs/distilbert/y_test.csv\",\n",
    "    y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilitiy function for heatmap of a confusion matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_heatmap(confusion_matrix, labels):\n",
    "    ax = sns.heatmap(\n",
    "        confusion_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "    )\n",
    "    ax.set(xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "The classification apporach now utilized cross validation to get a better estimate of the model's performance. The model is trained on 5 different folds of the data. The model is then evaluated on the validation set of each fold. The model with the best validation score is then used to make predictions on the test set. The test set predictions are then used to calculate the test set score. The test set score is the final score of the model. The detailed results are in the one_hot_standalone_cross_validation_results.csv file.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
